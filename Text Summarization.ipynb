{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization Using NLTK:\n",
    "\n",
    "The provided code extracts a summary from a given text by first tokenizing the text into words and sentences. It then filters out common stopwords and calculates the frequency of each remaining word. Next, it assigns a value to each sentence based on the frequency of important words it contains. Finally, it selects and outputs sentences with values above a certain threshold (1.2 times the average sentence value) to create a summary of the text.\n",
    "\n",
    "The steps that will be implemented are:\n",
    "\n",
    "1- tokenization of text and sentences\n",
    "2- Frequency table for words\n",
    "3- creating a score for each sentence (sum of word frequencies)\n",
    "4- Average Sentence Value\n",
    "5- Select sentences with values > 1.2 * Average and adding them to the summary\n",
    "\n",
    "--> basically we select the sentences that have higher score based on its words if they are highly frequent and using a threshold, we choose if that sentence is worth it to be added in the summary or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Wajih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wajih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"During my studies, I was able to acquire a set of faculties that enabled me to reinforce my skills in multiple areas: a significant knowledge of the fundamentals of Python in order to implement data science techniques and to build machine learning as well as deep learning models. In addition, my study experience was also reinforced by a series of online courses that delved into web scraping, data analytics and projects in machine learning and time series Analysis. Added to that, I am extremely familiar with SQL to manage data and also data visualization tools like Power BI in order to come up with insights and well-structured decisions. Moreover, my experience with ‘EY Tunisia’ was a golden ticket to develop dashboards and reports that can help analyze business performance and processes using Python and Power BI. In fact, I implemented different techniques to transform data into insights that drive business value. It was an enriching opportunity to delve into the professional world in an efficient way Added to that, my last job in Tunisia as business consultant is an enriching opportunity to delve into the professional world in an efficient way. Besides, starting a professional experience as an international freelancer in the field of data analytics was an asset for me to connect with employers from all over the world. Thus, joining your company would be an experience in perfect match with my ambitions, especially since I am very serious about enhancing my work capabilities besides the fact that I am very motivated and ready to invest my time to integrate successfully the team and to be a driving force in your approach to work.\n",
    "Please find the attached Curriculum Vitae.\n",
    "Thank you in advance for your time and I am at your disposal for any further information and interview. Hoping that my application will hold your attention and in anticipation of a reply, which I hope is favorable, please accept my sincere greetings.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement creates a set called stopWords that contains a list of common \"stopwords\" (like \"the\", \"is\", \"in\") from the English language, obtained from the stopwords module of the nltk library. The stopwords.words(\"english\") function fetches these stopwords in the form of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'its', 'further', 'whom', 'few', 'isn', 'needn', 'your', \"you'd\", 'does', 'mustn', 'can', 'itself', 'own', 'ours', 'doing', 'during', 'more', 'will', 'hers', 'it', 'is', 'couldn', 'each', 'not', \"doesn't\", 'if', \"weren't\", 'as', 'yourself', 'what', 'who', 'up', 'with', 'he', 'only', 'theirs', 'hasn', 'they', 'has', \"mightn't\", 'then', 'are', 'too', 'now', 'through', 'do', 'm', 'yours', 'against', 'most', 'don', 'about', 'them', 'into', 'shouldn', 'd', 'ourselves', 'until', \"it's\", 'were', 'between', \"wasn't\", 'off', 'very', 'hadn', \"isn't\", 'myself', 'ain', 'be', 'there', 'or', 'our', 'than', 'other', 'll', 'out', 'me', \"couldn't\", 'herself', 'below', 'him', 'which', 'both', \"don't\", \"haven't\", 'any', \"hadn't\", 'just', 'at', 'on', 'this', 'was', 'when', 'and', \"that'll\", 'where', 'again', 'wouldn', 'yourselves', 'having', 'same', 'some', 'didn', 'aren', 'to', \"mustn't\", 'here', 'ma', 've', 'she', 'shan', 'the', 'while', 'such', 't', 'my', 'i', 'of', \"aren't\", \"won't\", 'that', \"wouldn't\", 'you', 'being', 're', 'after', 'haven', 'a', 'no', 'nor', 'o', 'an', 'her', 'from', 's', 'himself', 'did', 'had', 'before', 'over', \"shouldn't\", 'why', 'so', 'these', 'doesn', \"you'll\", 'wasn', \"didn't\", \"hasn't\", 'been', 'weren', 'those', \"you're\", 'themselves', 'under', 'won', 'but', 'once', 'by', 'have', \"you've\", \"she's\", 'their', 'down', 'mightn', 'am', 'because', 'all', \"should've\", 'above', 'for', 'we', 'in', 'his', 'y', \"shan't\", 'how', \"needn't\", 'should'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words(\"english\"))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word_tokenize function from the nltk library to split the input text into individual words or tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['During', 'my', 'studies', ',', 'I', 'was', 'able', 'to', 'acquire', 'a', 'set', 'of', 'faculties', 'that', 'enabled', 'me', 'to', 'reinforce', 'my', 'skills', 'in', 'multiple', 'areas', ':', 'a', 'significant', 'knowledge', 'of', 'the', 'fundamentals', 'of', 'Python', 'in', 'order', 'to', 'implement', 'data', 'science', 'techniques', 'and', 'to', 'build', 'machine', 'learning', 'as', 'well', 'as', 'deep', 'learning', 'models', '.', 'In', 'addition', ',', 'my', 'study', 'experience', 'was', 'also', 'reinforced', 'by', 'a', 'series', 'of', 'online', 'courses', 'that', 'delved', 'into', 'web', 'scraping', ',', 'data', 'analytics', 'and', 'projects', 'in', 'machine', 'learning', 'and', 'time', 'series', 'Analysis', '.', 'Added', 'to', 'that', ',', 'I', 'am', 'extremely', 'familiar', 'with', 'SQL', 'to', 'manage', 'data', 'and', 'also', 'data', 'visualization', 'tools', 'like', 'Power', 'BI', 'in', 'order', 'to', 'come', 'up', 'with', 'insights', 'and', 'well-structured', 'decisions', '.', 'Moreover', ',', 'my', 'experience', 'with', '‘', 'EY', 'Tunisia', '’', 'was', 'a', 'golden', 'ticket', 'to', 'develop', 'dashboards', 'and', 'reports', 'that', 'can', 'help', 'analyze', 'business', 'performance', 'and', 'processes', 'using', 'Python', 'and', 'Power', 'BI', '.', 'In', 'fact', ',', 'I', 'implemented', 'different', 'techniques', 'to', 'transform', 'data', 'into', 'insights', 'that', 'drive', 'business', 'value', '.', 'It', 'was', 'an', 'enriching', 'opportunity', 'to', 'delve', 'into', 'the', 'professional', 'world', 'in', 'an', 'efficient', 'way', 'Added', 'to', 'that', ',', 'my', 'last', 'job', 'in', 'Tunisia', 'as', 'business', 'consultant', 'is', 'an', 'enriching', 'opportunity', 'to', 'delve', 'into', 'the', 'professional', 'world', 'in', 'an', 'efficient', 'way', '.', 'Besides', ',', 'starting', 'a', 'professional', 'experience', 'as', 'an', 'international', 'freelancer', 'in', 'the', 'field', 'of', 'data', 'analytics', 'was', 'an', 'asset', 'for', 'me', 'to', 'connect', 'with', 'employers', 'from', 'all', 'over', 'the', 'world', '.', 'Thus', ',', 'joining', 'your', 'company', 'would', 'be', 'an', 'experience', 'in', 'perfect', 'match', 'with', 'my', 'ambitions', ',', 'especially', 'since', 'I', 'am', 'very', 'serious', 'about', 'enhancing', 'my', 'work', 'capabilities', 'besides', 'the', 'fact', 'that', 'I', 'am', 'very', 'motivated', 'and', 'ready', 'to', 'invest', 'my', 'time', 'to', 'integrate', 'successfully', 'the', 'team', 'and', 'to', 'be', 'a', 'driving', 'force', 'in', 'your', 'approach', 'to', 'work', '.', 'Please', 'find', 'the', 'attached', 'Curriculum', 'Vitae', '.', 'Thank', 'you', 'in', 'advance', 'for', 'your', 'time', 'and', 'I', 'am', 'at', 'your', 'disposal', 'for', 'any', 'further', 'information', 'and', 'interview', '.', 'Hoping', 'that', 'my', 'application', 'will', 'hold', 'your', 'attention', 'and', 'in', 'anticipation', 'of', 'a', 'reply', ',', 'which', 'I', 'hope', 'is', 'favorable', ',', 'please', 'accept', 'my', 'sincere', 'greetings', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a frequency table (freqTable) to count how often each word (excluding stopwords) appears in the list words. It first converts each word to lowercase to ensure case-insensitive counting, and then checks if the word is a stopword or already in the freqTable. If it's not a stopword and not in the table, it is added with a count of 1, or its count is incremented if it already exists in the table, and finally, the frequency table is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'studies': 1, ',': 12, 'able': 1, 'acquire': 1, 'set': 1, 'faculties': 1, 'enabled': 1, 'reinforce': 1, 'skills': 1, 'multiple': 1, 'areas': 1, ':': 1, 'significant': 1, 'knowledge': 1, 'fundamentals': 1, 'python': 2, 'order': 2, 'implement': 1, 'data': 6, 'science': 1, 'techniques': 2, 'build': 1, 'machine': 2, 'learning': 3, 'well': 1, 'deep': 1, 'models': 1, '.': 11, 'addition': 1, 'study': 1, 'experience': 4, 'also': 2, 'reinforced': 1, 'series': 2, 'online': 1, 'courses': 1, 'delved': 1, 'web': 1, 'scraping': 1, 'analytics': 2, 'projects': 1, 'time': 3, 'analysis': 1, 'added': 2, 'extremely': 1, 'familiar': 1, 'sql': 1, 'manage': 1, 'visualization': 1, 'tools': 1, 'like': 1, 'power': 2, 'bi': 2, 'come': 1, 'insights': 2, 'well-structured': 1, 'decisions': 1, 'moreover': 1, '‘': 1, 'ey': 1, 'tunisia': 2, '’': 1, 'golden': 1, 'ticket': 1, 'develop': 1, 'dashboards': 1, 'reports': 1, 'help': 1, 'analyze': 1, 'business': 3, 'performance': 1, 'processes': 1, 'using': 1, 'fact': 2, 'implemented': 1, 'different': 1, 'transform': 1, 'drive': 1, 'value': 1, 'enriching': 2, 'opportunity': 2, 'delve': 2, 'professional': 3, 'world': 3, 'efficient': 2, 'way': 2, 'last': 1, 'job': 1, 'consultant': 1, 'besides': 2, 'starting': 1, 'international': 1, 'freelancer': 1, 'field': 1, 'asset': 1, 'connect': 1, 'employers': 1, 'thus': 1, 'joining': 1, 'company': 1, 'would': 1, 'perfect': 1, 'match': 1, 'ambitions': 1, 'especially': 1, 'since': 1, 'serious': 1, 'enhancing': 1, 'work': 2, 'capabilities': 1, 'motivated': 1, 'ready': 1, 'invest': 1, 'integrate': 1, 'successfully': 1, 'team': 1, 'driving': 1, 'force': 1, 'approach': 1, 'please': 2, 'find': 1, 'attached': 1, 'curriculum': 1, 'vitae': 1, 'thank': 1, 'advance': 1, 'disposal': 1, 'information': 1, 'interview': 1, 'hoping': 1, 'application': 1, 'hold': 1, 'attention': 1, 'anticipation': 1, 'reply': 1, 'hope': 1, 'favorable': 1, 'accept': 1, 'sincere': 1, 'greetings': 1}\n"
     ]
    }
   ],
   "source": [
    "freqTable = dict()\n",
    "\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] =1\n",
    "print(freqTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement uses the sent_tokenize function from the nltk library to split the input text into individual sentences. The text variable is expected to be a string, and the function processes it to break the text into a list of sentences. The resulting list of sentences is assigned to the variable sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['During my studies, I was able to acquire a set of faculties that enabled me to reinforce my skills in multiple areas: a significant knowledge of the fundamentals of Python in order to implement data science techniques and to build machine learning as well as deep learning models.', 'In addition, my study experience was also reinforced by a series of online courses that delved into web scraping, data analytics and projects in machine learning and time series Analysis.', 'Added to that, I am extremely familiar with SQL to manage data and also data visualization tools like Power BI in order to come up with insights and well-structured decisions.', 'Moreover, my experience with ‘EY Tunisia’ was a golden ticket to develop dashboards and reports that can help analyze business performance and processes using Python and Power BI.', 'In fact, I implemented different techniques to transform data into insights that drive business value.', 'It was an enriching opportunity to delve into the professional world in an efficient way Added to that, my last job in Tunisia as business consultant is an enriching opportunity to delve into the professional world in an efficient way.', 'Besides, starting a professional experience as an international freelancer in the field of data analytics was an asset for me to connect with employers from all over the world.', 'Thus, joining your company would be an experience in perfect match with my ambitions, especially since I am very serious about enhancing my work capabilities besides the fact that I am very motivated and ready to invest my time to integrate successfully the team and to be a driving force in your approach to work.', 'Please find the attached Curriculum Vitae.', 'Thank you in advance for your time and I am at your disposal for any further information and interview.', 'Hoping that my application will hold your attention and in anticipation of a reply, which I hope is favorable, please accept my sincere greetings.']\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates a \"value\" for each sentence in the sentences list based on the frequency of important words, which are stored in the freqTable. For each sentence, the function checks if any word from freqTable appears in the sentence, and if so, adds the word's frequency to the sentence's value. The final result is a dictionary (sentenceValue) where each key is a sentence, and its value is the sum of the frequencies of the words it contains, which is then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'During my studies, I was able to acquire a set of faculties that enabled me to reinforce my skills in multiple areas: a significant knowledge of the fundamentals of Python in order to implement data science techniques and to build machine learning as well as deep learning models.': 61, 'In addition, my study experience was also reinforced by a series of online courses that delved into web scraping, data analytics and projects in machine learning and time series Analysis.': 61, 'Added to that, I am extremely familiar with SQL to manage data and also data visualization tools like Power BI in order to come up with insights and well-structured decisions.': 52, 'Moreover, my experience with ‘EY Tunisia’ was a golden ticket to develop dashboards and reports that can help analyze business performance and processes using Python and Power BI.': 52, 'In fact, I implemented different techniques to transform data into insights that drive business value.': 44, 'It was an enriching opportunity to delve into the professional world in an efficient way Added to that, my last job in Tunisia as business consultant is an enriching opportunity to delve into the professional world in an efficient way.': 49, 'Besides, starting a professional experience as an international freelancer in the field of data analytics was an asset for me to connect with employers from all over the world.': 51, 'Thus, joining your company would be an experience in perfect match with my ambitions, especially since I am very serious about enhancing my work capabilities besides the fact that I am very motivated and ready to invest my time to integrate successfully the team and to be a driving force in your approach to work.': 59, 'Please find the attached Curriculum Vitae.': 17, 'Thank you in advance for your time and I am at your disposal for any further information and interview.': 19, 'Hoping that my application will hold your attention and in anticipation of a reply, which I hope is favorable, please accept my sincere greetings.': 38}\n"
     ]
    }
   ],
   "source": [
    "def getsentenceValue():\n",
    "    sentenceValue = dict()\n",
    "    for sentence in sentences:\n",
    "        for word,freq in freqTable.items():\n",
    "            if word in sentence.lower():\n",
    "                if sentence in sentenceValue:\n",
    "                    sentenceValue[sentence] +=freq\n",
    "                else:\n",
    "                    sentenceValue[sentence] = freq\n",
    "    return(sentenceValue)\n",
    "    \n",
    "sentenceValue= getsentenceValue()\n",
    "print(sentenceValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The getsumValues() function calculates the total value of all sentences in sentenceValue and then computes the average by dividing the total by the number of sentences. It returns the average sentence value as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "def getsumValues():\n",
    "    sumValues = 0\n",
    "    for sentence in sentenceValue:\n",
    "        sumValues += sentenceValue[sentence]\n",
    "    \n",
    "    average = int(sumValues/len(sentenceValue))\n",
    "    return average\n",
    "\n",
    "average = getsumValues()\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a summary by selecting sentences from sentences where the sentence value is greater than 1.2 times the average sentence value. It checks if the sentence is in sentenceValue and if its value exceeds the threshold, then adds it to the summary string. Finally, the summary is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " During my studies, I was able to acquire a set of faculties that enabled me to reinforce my skills in multiple areas: a significant knowledge of the fundamentals of Python in order to implement data science techniques and to build machine learning as well as deep learning models. In addition, my study experience was also reinforced by a series of online courses that delved into web scraping, data analytics and projects in machine learning and time series Analysis. Thus, joining your company would be an experience in perfect match with my ambitions, especially since I am very serious about enhancing my work capabilities besides the fact that I am very motivated and ready to invest my time to integrate successfully the team and to be a driving force in your approach to work.\n"
     ]
    }
   ],
   "source": [
    "summary = ''\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "        summary += \" \" + sentence\n",
    "\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
